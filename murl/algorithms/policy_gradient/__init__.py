from murl.algorithms.policy_gradient.ppo import PPO

policy_gradient_algorithms = {"ppo": PPO}
